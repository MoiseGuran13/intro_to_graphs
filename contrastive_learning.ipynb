{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import torch\n",
    "import torch_geometric\n",
    "from utils import vis_grid, vis_from_pyg\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "dataset = MoleculeNet(\"datasets/\", \"BACE\")\n",
    "atom_dims = dataset.num_node_features\n",
    "bond_dims = dataset.num_edge_features\n",
    "\n",
    "# Convert dataset to a list of Data objects\n",
    "data_list = list(dataset)\n",
    "# Shuffle (these datasets have all the labels at one end)\n",
    "random.shuffle(data_list)\n",
    "dataset = data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to make it a dataloader, instead of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop, val_prop, test_prop = 0.6, 0.2, 0.2\n",
    "n_train, n_val, n_test = int(train_prop*len(dataset)), int(val_prop*len(dataset)), int(test_prop*len(dataset))\n",
    "train, val, test = dataset[:n_train], dataset[n_train:-n_test], dataset[-n_test:]\n",
    "train_loader = DataLoader(train, batch_size = 128, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size = 128, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model\n",
    "\n",
    "See `graph_tasks.ipynb` for more details + implementation stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GenericEncoder, GNNBlock, GraphModel\n",
    "\n",
    "out_dim   = 1 # Binary classification\n",
    "\n",
    "emb_dim = 128\n",
    "n_layers = 5\n",
    "\n",
    "atom_encoder = GenericEncoder(emb_dim, atom_dims)\n",
    "bond_encoder = GenericEncoder(emb_dim, bond_dims)\n",
    "out_layer    = GenericEncoder(emb_dim, emb_dim)\n",
    "gnn_block = GNNBlock(emb_dim, n_layers, 0.1)\n",
    "\n",
    "model = GraphModel(atom_encoder,\n",
    "                   bond_encoder,\n",
    "                   gnn_block,\n",
    "                   out_layer)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive learning\n",
    "\n",
    "Contrastive learning is a semi-supervised representation learning technique.\n",
    "\n",
    "In its simplest form (like here) it goes like this:\n",
    "\n",
    "1. Take an input sample (graph)\n",
    "2. Augment it in some way, two times (for example drop some edges)\n",
    "3. Plug both into the encoder\n",
    "4. Calculate loss based on how close together the two augmentations are\n",
    "\n",
    "### Augmentation\n",
    "\n",
    "We'll just be using random edge dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "def drop_edges_randomly(data, drop_ratio):\n",
    "    edge_index = data.edge_index  # [2, num_edges] tensor\n",
    "    num_edges = edge_index.size(1)\n",
    "    \n",
    "    # Determine how many edges to drop\n",
    "    num_edges_to_drop = int(drop_ratio * num_edges)\n",
    "    drop_indices = edge_index[:num_edges_to_drop]  # Select the first 'num_edges_to_drop' indices\n",
    "\n",
    "    # Mask the edges to keep\n",
    "    mask = torch.ones(num_edges, dtype=torch.bool)\n",
    "    mask[drop_indices] = False\n",
    "\n",
    "    # Keep only the edges that were not dropped\n",
    "    new_edge_index = edge_index[:, mask]\n",
    "\n",
    "    if 'edge_attr' in data:\n",
    "        edge_attr = data.edge_attr  # [num_edges, num_features]\n",
    "        new_edge_attr = edge_attr[mask]  # Keep attributes of the remaining edges\n",
    "    else:\n",
    "        new_edge_attr = None\n",
    "\n",
    "    # Create a new graph with the remaining edges and their attributes\n",
    "    new_data = data.clone()\n",
    "    new_data.edge_index = new_edge_index\n",
    "    new_data.edge_attr = new_edge_attr\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_grid(dataset[:2] + [drop_edges_randomly(d, 0.5) for d in dataset[:2]], filename=\"ogbg\", save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the loss function\n",
    "\n",
    "This is from [GraphCL](https://arxiv.org/abs/2010.13902) but you could also use `torch.functional.cosine_similarity`.\n",
    "\n",
    "It computes the similarity between embeddings for all pairs of graphs, then promotes the pairs of augmentations of the same sample that should have similar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl_loss(x1, x2):\n",
    "    # CL loss from GraphCL\n",
    "\n",
    "    T = 0.5\n",
    "    batch_size, _ = x1.size()\n",
    "\n",
    "    x1_abs = x1.norm(dim=1)\n",
    "    x2_abs = x2.norm(dim=1)\n",
    "\n",
    "    sim_matrix = torch.einsum('ik,jk->ij', x1, x2) / torch.einsum('i,j->ij', x1_abs, x2_abs)\n",
    "    sim_matrix = torch.exp(sim_matrix / T)\n",
    "    pos_sim = sim_matrix[range(batch_size), range(batch_size)]\n",
    "    loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "    loss = - torch.log(loss).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "This is a very minimal example, in reality training would be over a much larger dataset and for much more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# This is from my own work\n",
    "def train_epoch_random_edges(dataloader,\n",
    "                      model, model_optimizer,\n",
    "                      drop_proportion = 0.2):\n",
    "    \"\"\"\n",
    "    single train epoch for encoder with random edge dropping as augmentation\n",
    "    Args:\n",
    "        dataloader: dataloader (see get_train_loader)\n",
    "        model: encoder\n",
    "        model_optimizer: optimizer for model\n",
    "        model_loss_all: stores losses for each batch\n",
    "\n",
    "    Returns:\n",
    "        model_loss_all: loss for epoch\n",
    "    \"\"\"\n",
    "    model_loss_all = 0.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    for batch in tqdm(dataloader, leave = False):\n",
    "        # set up\n",
    "        batch = batch.to(device)\n",
    "        # # train (model) to minimize contrastive loss\n",
    "        model.train()\n",
    "        # view_learner.eval()\n",
    "        model.zero_grad()\n",
    "        # Need to augment each sample twice\n",
    "        aug1 = drop_edges_randomly(batch.clone(), drop_proportion)\n",
    "        aug2 = drop_edges_randomly(batch.clone(), drop_proportion)\n",
    "\n",
    "        x_aug_1 = model(aug1)\n",
    "        x_aug_2 = model(aug2)\n",
    "\n",
    "        model_loss = cl_loss(x_aug_1, x_aug_2) #\n",
    "        # model_loss = model.calc_loss(x_aug_1, x_aug_2)\n",
    "        model_loss_all += model_loss.item() * batch.num_graphs\n",
    "\n",
    "        # standard gradient descent formulation\n",
    "        model_loss.backward()\n",
    "        model_optimizer.step()\n",
    "\n",
    "    return model_loss_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "At the moment this just calculates loss. What would be a better validation metric?\n",
    "\n",
    "**Implement a better validation metric**\n",
    "\n",
    "*(Hint: The dataset has its own classification task)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is from my own work\n",
    "def val_epoch_random_edges(dataloader,\n",
    "                      model, model_optimizer,\n",
    "                      drop_proportion = 0.2):\n",
    "    model_loss_all = 0.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, leave = False):\n",
    "            # set up\n",
    "            batch = batch.to(device)\n",
    "            # # train (model) to minimize contrastive loss\n",
    "            model.eval()\n",
    "\n",
    "            aug1 = drop_edges_randomly(batch.clone(), drop_proportion)\n",
    "            aug2 = drop_edges_randomly(batch.clone(), drop_proportion)\n",
    "\n",
    "            x_aug_1 = model(aug1)\n",
    "            x_aug_2 = model(aug2)\n",
    "        \n",
    "\n",
    "            model_loss = cl_loss(x_aug_1, x_aug_2) #\n",
    "            # model_loss = model.calc_loss(x_aug_1, x_aug_2)\n",
    "            model_loss_all += model_loss.item() * batch.num_graphs\n",
    "\n",
    "    return model_loss_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "- Define parameters\n",
    "- Track losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 5\n",
    "drop_proportion = 0.1\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model_train_losses = []\n",
    "model_val_losses = []\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch_n in pbar:\n",
    "    model_loss_all = train_epoch_random_edges(train_loader,\n",
    "                                                model, model_optimizer,\n",
    "                                                drop_proportion=drop_proportion)\n",
    "    model_train_losses.append(model_loss_all)\n",
    "    \n",
    "    if epoch_n % 5 == 0:\n",
    "        val_loss_all = train_epoch_random_edges(train_loader,\n",
    "                                                    model, model_optimizer,\n",
    "                                                    drop_proportion=drop_proportion)\n",
    "        model_val_losses.append(val_loss_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The point of representation learning is to learn good... representations. Incredible.\n",
    "\n",
    "This, in practise, can mean two things:\n",
    "\n",
    "- Predict properties + perform tasks without any more training (zero-shot)\n",
    "- Train on supervised tasks faster (few-shot)\n",
    "- Perform better on new data (transfer)\n",
    "\n",
    "*These are not official definitions*\n",
    "\n",
    "Here we load a different molecule dataset (BBBP) with a binary classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeNet(\"datasets/\", \"BBBP\")\n",
    "atom_dims = dataset.num_node_features\n",
    "bond_dims = dataset.num_edge_features\n",
    "\n",
    "# Convert dataset to a list of Data objects\n",
    "data_list = list(dataset)\n",
    "# Shuffle (these datasets have all the labels at one end)\n",
    "random.shuffle(data_list)\n",
    "dataset = data_list\n",
    "\n",
    "train_prop, val_prop, test_prop = 0.6, 0.2, 0.2\n",
    "n_train, n_val, n_test = int(train_prop*len(dataset)), int(val_prop*len(dataset)), int(test_prop*len(dataset))\n",
    "train, val, test = dataset[:n_train], dataset[n_train:-n_test], dataset[-n_test:]\n",
    "train_loader = DataLoader(train, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-shot learning, we need embeddings. These are the representations the model has learnt to produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def get_embeddings(encoder, loader):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        # Your code here!\n",
    "        # Except my code is already here\n",
    "        # If you're a very keen kid you could improve this with concatenation and other optimisations\n",
    "        for batch in tqdm(loader):\n",
    "            embedding = encoder.forward(batch)\n",
    "            embeddings.append(embedding)\n",
    "            labels.append(batch.y)\n",
    "\n",
    "    # Produce one big tensor of embeddings and labels\n",
    "    embeddings = torch.concatenate(embeddings, 0)\n",
    "    labels = torch.concatenate(labels)\n",
    "    # Move to numpy arrays for the later stuff\n",
    "    return embeddings.cpu().numpy(), labels.cpu().numpy()\n",
    "\n",
    "train_emb, train_y = get_embeddings(model, train_loader)\n",
    "val_emb, val_y = get_embeddings(model, val_loader)\n",
    "test_emb, test_y = get_embeddings(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "We now have embeddings and labels for these molecules - but they're very high dimensional `emb_dim`D.\n",
    "We can only really visualise 2D, so use [dimensionality reduction](https://medium.com/@alexowendavies/understanding-dimensionality-reduction-b319a6e60c80) to drop that down to 2D.\n",
    "\n",
    "We can colour according to the molecule's label (what we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "\n",
    "# This is lazy. Fiddle with the parameters - what changes? What does that mean? What?\n",
    "tsne = TSNE().fit_transform(train_emb)\n",
    "\n",
    "ax.scatter(tsne[:,0], tsne[:,1], c = train_y[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models\n",
    "\n",
    "How well does a support vector classifier *(a kind of linear model)* predict this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "lin_classifier = SVC()\n",
    "lin_classifier.fit(train_emb, train_y[:,0])\n",
    "\n",
    "pred_test = lin_classifier.predict(test_emb).flatten()\n",
    "test_y = test_y[:,0].flatten()\n",
    "\n",
    "correct = np.sum(pred_test == test_y)\n",
    "print(f\"Accuracy: {100 * correct / pred_test.shape[0]}\")\n",
    "print(f\"Class weighting: {np.sum(test_y) / test_y.shape[0]}\")\n",
    "print(f\"ROC: {roc_auc_score(test_y, pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
