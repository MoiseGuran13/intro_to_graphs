{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from utils import vis_grid, vis_from_pyg\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "dataset = MoleculeNet(\"datasets/\", \"BACE\")\n",
    "atom_dims = dataset.num_node_features\n",
    "bond_dims = dataset.num_edge_features\n",
    "\n",
    "# Convert dataset to a list of Data objects\n",
    "data_list = list(dataset)\n",
    "# Shuffle (these datasets have all the labels at one end)\n",
    "random.shuffle(data_list)\n",
    "dataset = data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to make it a dataloader, instead of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop, val_prop, test_prop = 0.6, 0.2, 0.2\n",
    "n_train, n_val, n_test = int(train_prop*len(dataset)), int(val_prop*len(dataset)), int(test_prop*len(dataset))\n",
    "train, val, test = dataset[:n_train], dataset[n_train:-n_test], dataset[-n_test:]\n",
    "train_loader = DataLoader(train, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a model\n",
    "\n",
    "A graph model has a few parts:\n",
    "- Projection heads: Learn to map node and edge features to a new space (often linear layers)\n",
    "- GNN layers: Graph layers. Here we'll use message passing layers, but graph transformers are also an option.\n",
    "- Pooling: Aggregate the node embeddings of the GNN layers into one vector.\n",
    "- Output: Standard output stuff, vector to output space.\n",
    "\n",
    "We'll work through part-by-part, then bring them together to get a model.\n",
    "\n",
    "First we'll do the node/edge feature encoders. These are just a few linear layers, where we specify input and output size.\n",
    "\n",
    "*We'll also use this as an output layer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "import numpy as np\n",
    "\n",
    "class GenericEncoder(torch.nn.Module):\n",
    "\t\"\"\"\n",
    "\tA generic encoder module that transforms input features into embeddings.\n",
    "\n",
    "\tArgs:\n",
    "\t\temb_dim (int): The dimensionality of the output embeddings.\n",
    "\t\tfeat_dim (int): The dimensionality of the input features.\n",
    "\t\tn_layers (int, optional): The number of layers in the encoder. Defaults to 1.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, emb_dim, feat_dim, n_layers=1):\n",
    "\t\tsuper(GenericEncoder, self).__init__()\n",
    "\t\tself.layers = []\n",
    "\t\tspread_layers = [min(emb_dim, feat_dim) + np.abs(feat_dim - emb_dim) * i for i in range(n_layers - 1)]\n",
    "\n",
    "\t\tlayer_sizes = [feat_dim] + spread_layers + [emb_dim]\n",
    "\t\tfor i in range(n_layers):\n",
    "\t\t\tlin = Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(lin.weight.data)\n",
    "\t\t\tself.layers.append(lin)\n",
    "\n",
    "\t\t\tif i != n_layers: # i will never be n_layers but ok\n",
    "\t\t\t\tself.layers.append(ReLU())\n",
    "\n",
    "\t\tself.model = Sequential(*self.layers)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t\"\"\"\n",
    "\t\tForward pass of the encoder.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tx (torch.Tensor): Input features.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\ttorch.Tensor: Output embeddings.\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.model(x.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the GNN part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "# Generic N-Layer Graph Isomorphism Network encoder\n",
    "class GNNBlock(torch.nn.Module):\n",
    "    def __init__(self, emb_dim=300, num_gc_layers=5, drop_ratio=0.0):\n",
    "        super(GNNBlock, self).__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_gc_layers = num_gc_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.out_node_dim = self.emb_dim\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convolution = GINEConv\n",
    "\n",
    "        for i in range(num_gc_layers):\n",
    "            nn = Sequential(Linear(emb_dim, 2 * emb_dim), torch.nn.BatchNorm1d(2 * emb_dim), ReLU(),\n",
    "                            Linear(2 * emb_dim, emb_dim))\n",
    "            conv = GINEConv(nn)\n",
    "            bn = torch.nn.BatchNorm1d(emb_dim)\n",
    "            self.convs.append(conv)\n",
    "            self.bns.append(bn)\n",
    "\n",
    "    def init_emb(self):\n",
    "        \"\"\"\n",
    "        Initializes the node embeddings.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, batch, x, edge_index, edge_attr):\n",
    "        # compute node embeddings using GNN\n",
    "        xs = []\n",
    "        for i in range(self.num_gc_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "\n",
    "            if i == self.num_gc_layers - 1:\n",
    "                # remove relu for the last layer\n",
    "                x = F.dropout(x, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                x = F.dropout(F.relu(x), self.drop_ratio, training=self.training)\n",
    "            xs.append(x)\n",
    "        return x, xs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv\n",
    "\n",
    "# Generic N-Layer Graph Isomorphism Network encoder\n",
    "class GraphModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_encoder,\n",
    "                 edge_encoder,\n",
    "                 gnn_block,\n",
    "                 output_layer,\n",
    "                 pooling_type = \"standard\"):\n",
    "        super(GraphModel, self).__init__()\n",
    "\n",
    "        self.node_encoder = node_encoder\n",
    "        self.edge_encoder = edge_encoder\n",
    "        self.gnn_block = gnn_block\n",
    "        self.output_layer = output_layer\n",
    "        self.pooling_type = pooling_type\n",
    "\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        \"\"\"\n",
    "        Initializes the node embeddings.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # print(data.x, data.edge_attr)\n",
    "        x = data.x\n",
    "        edge_attr = data.edge_attr\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        x = self.node_encoder.forward(x)\n",
    "        edge_attr = self.edge_encoder.forward(edge_attr)\n",
    "\n",
    "\n",
    "        x, xs = self.gnn_block.forward(batch, x, edge_index, edge_attr)\n",
    "\n",
    "        # compute graph embedding using pooling\n",
    "        if self.pooling_type == \"standard\":\n",
    "            xpool = global_add_pool(x, batch)\n",
    "            \n",
    "\n",
    "        elif self.pooling_type == \"layerwise\":\n",
    "            xpool = [global_add_pool(x, batch) for x in xs]\n",
    "            xpool = torch.cat(xpool, 1)\n",
    "            \n",
    "\n",
    "        x = self.output_layer.forward(xpool)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModel(\n",
      "  (node_encoder): GenericEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=9, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (edge_encoder): GenericEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (gnn_block): GNNBlock(\n",
      "    (convs): ModuleList(\n",
      "      (0-2): 3 x GINEConv(nn=Sequential(\n",
      "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      ))\n",
      "    )\n",
      "    (bns): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): GenericEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "out_dim   = 1 # Binary classification\n",
    "\n",
    "emb_dim = 64\n",
    "n_layers = 3\n",
    "\n",
    "atom_encoder = GenericEncoder(emb_dim, atom_dims)\n",
    "bond_encoder = GenericEncoder(emb_dim, bond_dims)\n",
    "out_layer    = GenericEncoder(out_dim, emb_dim)\n",
    "gnn_block = GNNBlock(emb_dim, n_layers, 0.1)\n",
    "\n",
    "model = GraphModel(atom_encoder,\n",
    "                   bond_encoder,\n",
    "                   gnn_block,\n",
    "                   out_layer)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Validation Accuracy: 55.59%\n",
      "Dataset weighting: 0.4440789473684211\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=0.001):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    training_records, validation_records = [], []\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    validation_records.append(validate_model(model, val_loader))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, data.y.float().view(-1, 1))\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        training_records.append(running_loss/len(train_loader))\n",
    "        \n",
    "        # Print epoch loss\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "        if epoch % 10 == 0:\n",
    "        # Validate the model\n",
    "            validation_records.append(validate_model(model, val_loader))\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return training_records, validation_records\n",
    "\n",
    "# Define the validation function\n",
    "def validate_model(model, val_loader, testing=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        trues = []\n",
    "        for data in val_loader:\n",
    "            outputs = model(data)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            preds += predicted.numpy().tolist()\n",
    "            trues += data.y.numpy().tolist()\n",
    "    \n",
    "    correct = np.sum(np.array(preds) == np.array(trues))\n",
    "    total = len(preds)\n",
    "    print(f'{\"Testing\" if testing else \"Validation\"} Accuracy: {100 * correct / total:.2f}%')\n",
    "    weighting = np.sum(trues) / len(trues)\n",
    "    print(f\"Dataset weighting: {weighting}\")\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "# Train the model\n",
    "tr, vr = train_model(model, train_loader, val_loader, 130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Visualise the validation and train loss\n",
    "- Write a `test_model` function to run over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 54.97%\n",
      "Dataset weighting: 0.4503311258278146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5496688741721855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(tr, color=\"r\")\n",
    "plt.plot([i*10 for i in range(len(vr))], vr, color=\"b\")\n",
    "plt.show()\n",
    "\n",
    "validate_model(model, test_loader, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another exercise\n",
    "\n",
    "**ESOL** is a regression dataset, predicting the solubility of various molecules. Adapt the above code for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MoleculeNet(\"datasets/\", \"ESOL\")\n",
    "atom_dims = dataset.num_node_features\n",
    "bond_dims = dataset.num_edge_features\n",
    "\n",
    "# Convert dataset to a list of Data objects\n",
    "data_list = list(dataset)\n",
    "# Shuffle (these datasets have all the labels at one end)\n",
    "random.shuffle(data_list)\n",
    "dataset = data_list\n",
    "\n",
    "train_prop, val_prop, test_prop = 0.6, 0.2, 0.2\n",
    "n_train, n_val, n_test = int(train_prop*len(dataset)), int(val_prop*len(dataset)), int(test_prop*len(dataset))\n",
    "train, val, test = dataset[:n_train], dataset[n_train:-n_test], dataset[-n_test:]\n",
    "train_loader = DataLoader(train, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 64, shuffle = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
